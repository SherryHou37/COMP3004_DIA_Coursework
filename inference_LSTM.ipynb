{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e167c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.miniTransformer import generate_square_subsequent_mask\n",
    "from models.miniTransformerV2 import TransformerChat\n",
    "import myTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b11f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenizer is loaded successfully: /tokenizer/tokenizerForHealthCare.pkl\n",
      "tokenizer done, with length 41978\n",
      "vocab size: 15000\n"
     ]
    }
   ],
   "source": [
    "from myTokenizer import myTokenizer\n",
    "ThisTokenizer = myTokenizer(num_words=15000)\n",
    "# ThisTokenizer.train_from_parquet(parquet_path='healthCare.parquet', inputCol='input', outputCol='output')\n",
    "# ThisTokenizer.save_tokenizer('/tokenizer/tokenizerForHealthCare.pkl')\n",
    "\n",
    "TOKENIZER = ThisTokenizer.load_tokenizer('/tokenizer/tokenizerForHealthCare.pkl')\n",
    "print(\"tokenizer done, with length\", len(TOKENIZER.word_index) + 1)\n",
    "print(\"vocab size:\", TOKENIZER.num_words)\n",
    "\n",
    "# word → index\n",
    "word2idx = TOKENIZER.word_index\n",
    "\n",
    "# index → word\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "# 注意：word_index 不会自动添加 <pad>，如果你在训练时加了 pad_idx=0，要手动加：\n",
    "word2idx[\"<pad>\"] = 0\n",
    "idx2word[0] = \"<pad>\"\n",
    "\n",
    "# src_vocab 和 trg_vocab 就是这个 word2idx（如果是共享词表的话）\n",
    "src_vocab = word2idx\n",
    "trg_vocab = word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb68a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BiLSTM import EncoderBiLSTM, DecoderLSTM, Seq2Seq, Attention\n",
    "\n",
    "# 假设你已经知道下面这些参数：\n",
    "vocab_size = TOKENIZER.num_words + 1  \n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "pad_idx = 0\n",
    "output_dim = vocab_size  # 生成任务，输出词表大小和输入相同\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "attn = Attention(hidden_dim)\n",
    "encoder = EncoderBiLSTM(vocab_size, embedding_dim, hidden_dim, pad_idx)\n",
    "decoder = DecoderLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx, attn)\n",
    "model = Seq2Seq(encoder, decoder, pad_idx=pad_idx, device=DEVICE).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cacdcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderBiLSTM(\n",
       "    (embedding): Embedding(15001, 256, padding_idx=0)\n",
       "    (lstm): LSTM(256, 512, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderLSTM(\n",
       "    (embedding): Embedding(15001, 256, padding_idx=0)\n",
       "    (lstm): LSTM(1280, 512, batch_first=True)\n",
       "    (fc_out): Linear(in_features=1536, out_features=15001, bias=True)\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载保存的参数\n",
    "model.load_state_dict(torch.load(\"checkpoint/weight_biLSTM_100.pth\", map_location=DEVICE))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a310a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, src_tensor, src_vocab, trg_vocab, device, max_len=50):\n",
    "    model.eval()\n",
    "\n",
    "    src_tensor = src_tensor.unsqueeze(0).to(device)  # [1, src_len]\n",
    "    mask = model.create_mask(src_tensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden, cell = model.encoder(src_tensor)\n",
    "\n",
    "        # 处理 hidden, cell 初始化\n",
    "        hidden = torch.tanh(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        cell = torch.tanh(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
    "        hidden = hidden[:, :, :model.decoder.decoder_hidden_dim]\n",
    "        cell = cell[:, :, :model.decoder.decoder_hidden_dim]\n",
    "\n",
    "    # 第一个 decoder 输入是 <sos>\n",
    "    trg_indices = [trg_vocab['<start>']]\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        prev_input = torch.LongTensor([trg_indices[-1]]).to(device)  # [1]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell, _ = model.decoder(prev_input, hidden, cell, encoder_outputs, mask)\n",
    "\n",
    "        next_token = output.argmax(1).item()\n",
    "        trg_indices.append(next_token)\n",
    "\n",
    "        if next_token == trg_vocab['<end>']:\n",
    "            break\n",
    "\n",
    "    # 去除 <sos> 和 <eos>\n",
    "    return trg_indices[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea0381d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", thank you for chat doctor . i have gone your query . understand your . in my opinion you should start . . . . is not to be out . . . of these symptoms to you to with of a . . to is family for\n"
     ]
    }
   ],
   "source": [
    "sentence = \"i love machine learning\"\n",
    "src_tokens = [src_vocab.get(tok, src_vocab['<UNKNOWN>']) for tok in sentence.split()]\n",
    "src_tensor = torch.LongTensor(src_tokens)\n",
    "\n",
    "output_ids = translate_sentence(model, src_tensor, src_vocab, trg_vocab, DEVICE)\n",
    "output_words = [idx2word[idx] for idx in output_ids]\n",
    "\n",
    "print(\" \".join(output_words))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
